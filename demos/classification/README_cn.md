[English](./README.md) | 简体中文

# Classification

- [Classification](#classification)
  - [1. 模型分类简介](#1-模型分类简介)
  - [2. 模型性能数据](#2-模型性能数据)
  - [3. 模型下载地址](#3-模型下载地址)
  - [4. 输入输出数据](#4-输入输出数据)
  - [5. PTQ 量化流程](#5-ptq-量化流程)


## 1. 模型分类简介

模型分类指的是将机器学习模型对**输入数据进行分类**的过程。具体来说，分类模型的任务是将输入数据（例如图像、文本、音频等）分配到预定义的类别中。这些类别通常是离散的标签，例如将图像分为“猫”或“狗”，或将电子邮件分类为“垃圾邮件”或“非垃圾邮件”。

在机器学习中，分类模型的训练过程包括以下几个步骤：

- **数据采集**：此过程包含图片采集和对应标签的标注。
- **数据预处理**：对数据进行清理和转换，以适应模型的输入要求（如图像大小裁剪缩放）。
- **特征提取**：从原始数据中提取有用的特征，通常是为了将数据转换为适合模型处理的格式（如将模型从 bgr 转换为 rgb，NCHW 转换为 NHWC 的通道排序）。
- **模型训练**：使用标记的数据训练分类模型，调整模型训练参数提高模型的检测精度和置信度。
- **模型验证**：使用验证集数据来评估模型的性能，并对模型进行微调和优化。
- **模型测试**：在测试集上评估模型的最终性能，确定其泛化能力。
- **部署和应用**：将训练好的模型进行模型量化和边缘侧板端部署。

深度学习的分类模型一般应用于将图片按其标签进行类别分类，最著名的图片分类挑战是 ImageNet Classification。 ImageNet Classification 是深度学习领域中的重要图像分类挑战，该数据集由斯坦福大学教授李飞飞及其团队于2007年构建，并于2009年在CVPR上发布。ImageNet 数据集广泛用于图像分类、检测和定位任务。

ILSVRC（ImageNet Large-Scale Visual Recognition Challenge）是基于 ImageNet 数据集的比赛，首次举办于2010年，直到2017年结束。该比赛包括图像分类、目标定位、目标检测、视频目标检测和场景分类。历届优胜者包括著名的深度学习模型，如 AlexNet、VGG、GoogLeNet 和 ResNet。ILSVRC2012 数据集是最常用的子集，包含1000个分类，每个分类约有1000张图片，总计约120万张训练图片，另外还有5万张验证图片和10万张测试图片（测试集没有标签）。

ImageNet 官方下载地址：https://image-net.org/

![](../../data/ImageNet.png)

由于该仓库提供的模型均是预训练模型进行模型转换后得到的 onnx/bin 文件，故无需再进行模型训练操作（缺乏训练资源也是一个很大的问题），由于数据集非常大，使用 ImageNet 数据集是作为后续模型量化操作中校准数据集的构建，下表是 ImageNet ILSVRC2012 数据集的大小情况：


| 数据集类型          | 类别   | 图片数量    |
| -------------- | ---- | ------- |
| ILSVRC2012 训练集 | 1000 | 120万张图片 |
| ILSVRC2012 验证集 | 1000 | 5万张图片   |
| ILSVRC2012 测试集 | 1000 | 10万张图片  |

ILSVRC2012 是ImageNet的子集，而ImageNet本身有超过1400多万张图片，超过2万多的分类。其中有超过100万张图片有明确类别标注和物体位置标注。

对于基于ImageNet的图像识别的结果评估，往往用到两个准确率的指标，一个是top-1准确率，一个是top-5准确率。**Top-1准确率指的是输出概率中最大的那一个对应的是正确类别的概率；top-5准确率指的是输出概率中最大的5个对应的5个类别中包含了正确类别的概率**。本仓库提供 Top-5 准确率类别预测，可以更明显的将模型的输出结果进行对比。

## 2. 模型性能数据

以下表格是在 RDK X5 & RDK X5 Module 上实际测试得到的性能数据，可以根据自己推理实际需要的性能和精度，对模型的大小做权衡取舍


| 架构         | 模型                       | 尺寸(像素)  | 类别数    | 参数量(M)  | 浮点Top-1 | 量化Top-1 | 延迟/吞吐量(单线程) | 延迟/吞吐量(多线程) | 帧率          |
| ----------- | -------------------------- | ----------- | -------- | --------- | --------- | --------- | ----------- | ----------- | ----------- |
| Transformer | EdgeNeXt_base              | 224x224     | 1000     | 18.51     | 78.21     | 74.52     | 8.80        | 32.31       | 113.35      |
|             | EdgeNeXt_small             | 224x224     | 1000     | 5.59      | 76.50     | 71.75     | 4.41        | 14.93       | 226.15      |
|             | **EdgeNeXt_x_small**       | **224x224** | **1000** | **2.34**  | **71.75** | **66.25** | **2.88**    | **9.63**    | **345.73**  |
|             | EdgeNeXt_xx_small          | 224x224     | 1000     | 1.33      | 69.50     | 64.25     | 2.47        | 7.24        | 403.49      |
|             | EfficientFormer_l3         | 224x224     | 1000     | 31.3      | 76.75     | 76.05     | 17.55       | 65.56       | 60.52       |
|             | **EfficientFormer_l1**     | **224x224** | **1000** | **12.3**  | **76.12** | **65.38** | **5.88**    | **20.69**   | **191.605** |
|             | EfficientFormerv2_s2       | 224x224     | 1000     | 12.6      | 77.50     | 70.75     | 6.99        | 26.01       | 152.40      |
|             | **EfficientFormerv2_s1**   | **224x224** | **1000** | **6.12**  | **77.25** | **68.75** | **4.24**    | **14.35**   | **275.95**  |
|             | EfficientFormerv2_s0       | 224x224     | 1000     | 3.57      | 74.25     | 68.50     | 5.79        | 19.96       | 198.45      |
|             | **EfficientViT_MSRA_m5**   | **224x224** | **1000** | **12.41** | **73.75** | **72.50** | **6.34**    | **22.69**   | **174.70**  |
|             | FastViT_SA12               | 224x224     | 1000     | 10.93     | 78.25     | 74.50     | 11.56       | 42.45       | 93.44       |
|             | FastViT_S12                | 224x224     | 1000     | 8.86      | 76.50     | 72.0      | 5.86        | 20.45       | 193.87      |
|             | **FastViT_T12**            | **224x224** | **1000** | **6.82**  | **74.75** | **70.43** | **4.97**    | **16.87**   | **234.78**  |
|             | FastViT_T8                 | 224x224     | 1000     | 3.67      | 73.50     | 68.50     | 2.09        | 5.93        | 667.21      |
| CNN         | ConvNeXt_nano              | 224x224     | 1000     | 15.59     | 77.37     | 71.75     | 5.71        | 19.80       | 200.18      |
|             | ConvNeXt_pico              | 224x224     | 1000     | 9.04      | 77.25     | 71.03     | 3.37        | 10.88       | 364.07      |
|             | **ConvNeXt_femto**         | **224x224** | **1000** | **5.22**  | **73.75** | **72.25** | **2.46**    | **7.11**    | **556.02**  |
|             | ConvNeXt_atto              | 224x224     | 1000     | 3.69      | 73.25     | 69.75     | 1.96        | 5.39        | 732.10      |
|             | FasterNet_S                | 224x224     | 1000     | 31.18     | 77.04     | 76.15     | 6.73        | 24.34       | 162.83      |
|             | FasterNet_T2               | 224x224     | 1000     | 15.04     | 76.50     | 76.05     | 3.39        | 11.56       | 342.48      |
|             | **FasterNet_T1**           | **224x224** | **1000** | **7.65**  | **74.29** | **71.25** | **1.96**    | **5.58**    | **708.40**  |
|             | FasterNet_T0               | 224x224     | 1000     | 3.96      | 71.75     | 68.50     | 1.41        | 3.48        | 1135.13     |
|             | RepVGG_B1g2                | 224x224     | 1000     | 41.36     | 77.78     | 68.25     | 9.77        | 36.19       | 109.61      |
|             | RepVGG_B1g4                | 224x224     | 1000     | 36.12     | 77.58     | 62.75     | 7.58        | 27.47       | 144.39      |
|             | RepVGG_B0                  | 224x224     | 1000     | 14.33     | 75.14     | 60.36     | 3.07        | 9.65        | 410.55      |
|             | RepVGG_A2                  | 224x224     | 1000     | 25.49     | 76.48     | 62.97     | 6.07        | 21.31       | 186.04      |
|             | **RepVGG_A1**              | **224x224** | **1000** | **12.78** | **74.46** | **62.78** | **2.67**    | **8.21**    | **482.20**  |
|             | RepVGG_A0                  | 224x224     | 1000     | 8.30      | 72.41     | 51.75     | 1.85        | 5.21        | 757.73      |
|             | RepViT_m1_1                | 224x224     | 1000     | 8.27      | 77.73     | 77.50     | 2.32        | 6.69        | 590.42      |
|             | **RepViT_m1_0**            | **224x224** | **1000** | **6.83**  | **76.75** | **76.50** | **1.97**    | **5.71**    | **692.29**  |
|             | RepViT_m0_9                | 224x224     | 1000     | 5.14      | 76.32     | 75.75     | 1.65        | 4.37        | 902.69      |
|             | MobileOne_S4               | 224x224     | 1000     | 14.82     | 78.75     | 76.50     | 4.58        | 15.44       | 256.52      |
|             | MobileOne_S3               | 224x224     | 1000     | 10.19     | 77.27     | 75.75     | 2.93        | 9.04        | 437.85      |
|             | MobileOne_S2               | 224x224     | 1000     | 7.87      | 74.75     | 71.25     | 2.11        | 6.04        | 653.68      |
|             | **MobileOne_S1**           | **224x224** | **1000** | **4.83**  | **72.31** | **70.45** | **1.31**    | **3.69**    | **1066.95** |
|             | **MobileOne_S0**           | **224x224** | **1000** | **2.15**  | **69.25** | **67.58** | **0.80**    | **1.59**    | **2453.17** |
|             | ResNet18                   | 224x224     | 1000     | 11.27     | 71.49     | 70.50     | 2.95        | 8.81        | 448.79      |
|             | ResNeXt50_32x4d            | 224x224     | 1000     | 24.99     | 76.25     | 76.00     | 5.89        | 20.90       | 189.61      |
|             | MobileNetv1                | 224x224     | 1000     | 1.33      | 71.74     | 65.36     | 1.27        | 2.90        | 1356.25     |
|             | **Mobilenetv2**            | **224x224** | **1000** | **3.44**  | **72.0**  | **68.17** | **1.42**    | **3.43**    | **1152.07** |
|             | **Mobilenetv3_large_100**  | **224x224** | **1000** | **5.47**  | **74.75** | **64.75** | **2.02**    | **5.53**    | **714.22**  |
|             | Mobilenetv4_conv_medium    | 224x224     | 1000     | 9.68      | 76.75     | 75.14     | 2.42        | 6.91        | 572.36      |
|             | **Mobilenetv4_conv_small** | **224x224** | **1000** | **3.76**  | **70.75** | **68.75** | **1.18**    | **2.74**    | **1436.22** |
|             | GoogLeNet                  | 224x224     | 1000     | 6.81      | 68.72     | 67.71     | 2.19        | 6.30        | 626.27      |


说明: 
1. X5的状态为最佳状态：CPU为8xA55@1.8G, 全核心Performance调度, BPU为1xBayes-e@1G, 共10TOPS等效int8算力。
2. 单线程延迟为单帧，单线程，单BPU核心的延迟，BPU推理一个任务最理想的情况。
3. 4线程工程帧率为4个线程同时向双核心BPU塞任务，一般工程中4个线程可以控制单帧延迟较小，同时吃满所有BPU到100%，在吞吐量(FPS)和帧延迟间得到一个较好的平衡。
4. 8线程极限帧率为8个线程同时向X3的双核心BPU塞任务，目的是为了测试BPU的极限性能，一般来说4核心已经占满，如果8线程比4线程还要好很多，说明模型结构需要提高"计算/访存"比，或者编译时选择优化DDR带宽。
5. 浮点/定点Top-1：浮点Top-1使用的是模型未量化前onnx的 Top-1 推理精度，量化Top-1则为量化后模型实际推理的精度。
6. 表格中粗体部分是在平衡推理速度和推理精度推荐选用的模型，可根据实际部署情况使用推理精度更高或推理速度更快的模型

## 3. 模型下载地址

分类模型的模型转换文件已经上传至云服务器中，可通过 wget 命令在服务器网站中下载：

服务器网站地址：https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_x5/

下载示例：

```shell
wget https://archive.d-robotics.cc/downloads/rdk_model_zoo/rdk_x5/EdgeNeXt_x_small_224x224_nv12.bin
```

模型下载shell脚本在各个分类模型的 model 文件夹中，可以执行 `sh download_bin.sh` 或 `sh download_onnx.sh` 命令下载 onnx/bin 文件。

## 4. 输入输出数据

- 输入数据

| 模型类别 | 输入数据  | 数据类型    | 数据形状              | 数据排布格式 |
| ---- | ----- | ------- | ----------------- | ------ |
| onnx | image | FLOAT32 | 1 x 3 x 224 x 224 | NCHW   |
| bin  | image | NV12    | 1 x 224 x 224 x 3 | NHWC   |

- 输出数据


| 模型类别 | 输出数据 | 数据类型 | 数据形状 | 数据排布格式 |
| ---- | ------- | ------- | -------- | ---- |
| onnx | classes | FLOAT32 | 1 x 1000 | NC   |
| bin  | classes | FLOAT32 | 1 x 1000 | NC   |


模型预训练的 pth 模型输入数据形状都为 `1x3x224x224` ，数据输出形状都为 `1x1000` ，符合 ImageNet 分类模型格式输出要求。具体到量化步骤，模型量化的 bin 文件输入数据格式都统一为 `nv12` ，模型预处理部分 `bpu_libdnn` 已内置格式转换函数，可直接调用改函数对模型数据进行处理。


## 5. PTQ 量化流程

模型量化是将神经网络的**浮点运算转换为定点运算**的技术，主要用于**减少计算复杂度和模型大小**，适用于资源受限的嵌入式设备，如智能手机、无人机和机器人。这些设备通常对内存、功耗和推理时间有严格要求，模型量化通过降低比特位来解决这些问题。

在常规精度模型中，通常使用FP32（32位浮点数）进行计算。然而，低精度模型（如INT8，8位定点整数）能够显著减小模型大小，并加快推理速度。混合精度模型则结合FP32和FP16，利用FP16减少内存使用，但在关键计算中仍保留FP32以保证准确性（即混合精度量化）。

**模型量化可以大幅减小模型大小**，例如INT8量化能使模型大小减少到原来的四分之一。这对存储空间有限的设备尤为重要。其次，量化模型通过减少内存占用，同时加快推理速度。此外，许多硬件加速器（如DSP和NPU）仅支持INT8运算，进一步凸显了量化的必要性。在工业界，INT8量化应用广泛，许多移动端推理框架如NCNN和TNN都支持此类模型的推理功能。通常，这些框架通过引入量化层（Quantize）和反量化层（Dequantize）来实现FP32与INT8之间的转换，从而在保证精度的同时优化模型的性能。

若开发者想要进一步了解板端的量化部分，文档也提供了[模型量化部署](./模型量化部署.md)的参考，为开发者提供了一个较为详细的量化步骤和流程方法。
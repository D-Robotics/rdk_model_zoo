{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a1dd4-1c89-44ad-83f5-bd004778e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024，WuChao D-Robotics.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "# from scipy.special import expit as sigmoid\n",
    "from time import time\n",
    "from hobot_dnn import pyeasy_dnn as dnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5626929-7670-474d-a01b-f2ba909f7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \n",
    "    \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \n",
    "    \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \n",
    "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \n",
    "    \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \n",
    "    \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \n",
    "    \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "    ]\n",
    "\n",
    "rdk_colors = [\n",
    "    (56, 56, 255), (151, 157, 255), (31, 112, 255), (29, 178, 255),(49, 210, 207), (10, 249, 72), (23, 204, 146), (134, 219, 61),\n",
    "    (52, 147, 26), (187, 212, 0), (168, 153, 44), (255, 194, 0),(147, 69, 52), (255, 115, 100), (236, 24, 0), (255, 56, 132),\n",
    "    (133, 0, 82), (255, 56, 203), (200, 149, 255), (199, 55, 255)]\n",
    "\n",
    "def draw_detection(img, box, score, class_id):\n",
    "    x1, y1, x2, y2 = box\n",
    "    color = rdk_colors[class_id%20]\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "    label = f\"{coco_names[class_id]}: {score:.2f}\"\n",
    "    (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    label_x = x1\n",
    "    label_y = y1 - 10 if y1 - 10 > label_height else y1 + 10\n",
    "    cv2.rectangle(\n",
    "        img, (label_x, label_y - label_height), (label_x + label_width, label_y + label_height), color, cv2.FILLED\n",
    "    )\n",
    "    cv2.putText(img, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "# matplotlib 绘制图像到 Jupyter Web\n",
    "from  matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def cv2_img2plt_img(cv2_img):\n",
    "    if cv2_img.ndim==3: # Color image, Convert BGR to RGB\n",
    "        return cv2_img[:,:,::-1] \n",
    "    else: # Grayscale image\n",
    "        return cv2_img\n",
    "\n",
    "def jshow(cv2_img, size=4):\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(cv2_img2plt_img(cv2_img), plt.cm.gray)\n",
    "    plt.show()\n",
    "\n",
    "def bgr2nv12_opencv(image):\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    area = height * width\n",
    "    yuv420p = cv2.cvtColor(image, cv2.COLOR_BGR2YUV_I420).reshape((area * 3 // 2,))\n",
    "    y = yuv420p[:area]\n",
    "    uv_planar = yuv420p[area:].reshape((2, area // 4))\n",
    "    uv_packed = uv_planar.transpose((1, 0)).reshape((area // 2,))\n",
    "    nv12 = np.zeros_like(yuv420p)\n",
    "    nv12[:height * width] = y\n",
    "    nv12[height * width:] = uv_packed\n",
    "    return nv12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02424175-5caa-482b-8313-21126ec4659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入bin模型\n",
    "model_path = \"ptq_models/yolov8x_detect_bayese_640x640_nv12_modified.bin\"\n",
    "begin_time = time()\n",
    "quantize_model = dnn.load(model_path)\n",
    "print(\"\\033[1;31m\" + f\"Load D-Robotics Quantize model time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(\"-> input tensors\")\n",
    "for i, quantize_input in enumerate(quantize_model[0].inputs):\n",
    "    print(f\"intput[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")\n",
    "\n",
    "print(\"-> output tensors\")\n",
    "for i, quantize_input in enumerate(quantize_model[0].outputs):\n",
    "    print(f\"output[{i}], name={quantize_input.name}, type={quantize_input.properties.dtype}, shape={quantize_input.properties.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018498f-49cd-4cae-a29c-332574c5bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提前将反量化系数准备好\n",
    "s_bboxes_scale = quantize_model[0].outputs[1].properties.scale_data[np.newaxis, :]\n",
    "m_bboxes_scale = quantize_model[0].outputs[3].properties.scale_data[np.newaxis, :]\n",
    "l_bboxes_scale = quantize_model[0].outputs[5].properties.scale_data[np.newaxis, :]\n",
    "print(f\"{s_bboxes_scale.shape=}, {m_bboxes_scale.shape=}, {l_bboxes_scale.shape=}\")\n",
    "\n",
    "# DFL求期望的系数, 只需要生成一次\n",
    "weights_static = np.array([i for i in range(16)]).astype(np.float32)[np.newaxis, np.newaxis, :]\n",
    "print(f\"{weights_static.shape = }\")\n",
    "\n",
    "# 输入图像大小, 一些阈值, 提前计算好\n",
    "REG = 16\n",
    "print(f\"{REG = }\")\n",
    "\n",
    "CLASSES_NUM = 80\n",
    "print(f\"{CLASSES_NUM = }\")\n",
    "\n",
    "SCORE_THRESHOLD = 0.25\n",
    "NMS_THRESHOLD = 0.7\n",
    "CONF_THRES_RAW = -np.log(1/SCORE_THRESHOLD - 1)\n",
    "print(\"SCORE_THRESHOLD  = %.2f, NMS_THRESHOLD = %.2f\"%(SCORE_THRESHOLD, NMS_THRESHOLD))\n",
    "print(\"CONF_THRES_RAW = %.2f\"%CONF_THRES_RAW)\n",
    "\n",
    "input_H, input_W = quantize_model[0].inputs[0].properties.shape[2:4]\n",
    "print(f\"{input_H = }, {input_W = }\")\n",
    "\n",
    "RESIZE_TYPE = 0\n",
    "LETTERBOX_TYPE = 1\n",
    "PREPROCESS_TYPE = LETTERBOX_TYPE\n",
    "print(\"LETTERBOX_TYPE\" if PREPROCESS_TYPE == LETTERBOX_TYPE else \"PREPROCESS_TYPE\")\n",
    "\n",
    "# grid, 只需要生成一次\n",
    "s_grid = np.stack([np.tile(np.linspace(0.5, 79.5, 80), reps=80), \n",
    "                     np.repeat(np.arange(0.5, 80.5, 1), 80)], axis=0).transpose(1,0)\n",
    "m_grid = np.stack([np.tile(np.linspace(0.5, 39.5, 40), reps=40), \n",
    "                     np.repeat(np.arange(0.5, 40.5, 1), 40)], axis=0).transpose(1,0)\n",
    "l_grid = np.stack([np.tile(np.linspace(0.5, 19.5, 20), reps=20), \n",
    "                     np.repeat(np.arange(0.5, 20.5, 1), 20)], axis=0).transpose(1,0)\n",
    "print(f\"{s_grid.shape = }  {m_grid.shape = }  {l_grid.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea37e9-0f36-4981-a9ed-bd8ca2123ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取一张bgr8格式的图像, 并进行可视化\n",
    "begin_time = time()\n",
    "img = cv2.imread(\"../../../../resource/datasets/COCO2017/assets/bus.jpg\")\n",
    "print(\"\\033[1;31m\" + f\"cv2.imread time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "print(f\"{img.shape = }\")\n",
    "jshow(img)\n",
    "\n",
    "img_h, img_w = img.shape[0:2]\n",
    "if PREPROCESS_TYPE == RESIZE_TYPE:\n",
    "    # 利用resize的方式进行前处理, 准备nv12的输入数据\n",
    "    begin_time = time()\n",
    "    input_tensor = cv2.resize(img, (input_W, input_H), interpolation=cv2.INTER_NEAREST) # 利用resize重新开辟内存节约一次\n",
    "    input_tensor = bgr2nv12_opencv(input_tensor)\n",
    "    y_scale = 1.0 * input_H / img_h\n",
    "    x_scale = 1.0 * input_W / img_w\n",
    "    y_shift = 0;\n",
    "    x_shift = 0;\n",
    "    print(\"\\033[1;31m\" + f\"pre process(resize) time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "    print(f\"{input_tensor.shape = }\")\n",
    "elif PREPROCESS_TYPE == LETTERBOX_TYPE:\n",
    "    # 利用 letter box 的方式进行前处理, 准备nv12的输入数据\n",
    "    begin_time = time()\n",
    "    x_scale = min(1.0 * input_H / img_h, 1.0 * input_W / img_w)\n",
    "    y_scale = x_scale\n",
    "    \n",
    "    if x_scale <= 0 or y_scale <= 0:\n",
    "        raise ValueError(\"Invalid scale factor.\")\n",
    "    \n",
    "    new_w = int(img_w * x_scale)\n",
    "    x_shift = (input_W - new_w) // 2\n",
    "    x_other = input_W - new_w - x_shift\n",
    "    \n",
    "    new_h = int(img_h * y_scale)\n",
    "    y_shift = (input_H - new_h) // 2\n",
    "    y_other = input_H - new_h - y_shift\n",
    "    \n",
    "    input_tensor = cv2.resize(img, (new_w, new_h))\n",
    "    \n",
    "    input_tensor = cv2.copyMakeBorder(input_tensor, y_shift, y_other, x_shift, x_other, cv2.BORDER_CONSTANT, value=[127, 127, 127])\n",
    "    input_tensor = bgr2nv12_opencv(input_tensor)\n",
    "    print(\"\\033[1;31m\" + f\"pre process(letter box) time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "    print(f\"{input_tensor.shape = }\")\n",
    "else:\n",
    "    print(f\"illegal PREPROCESS_TYPE = {PREPROCESS_TYPE}\")\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a71b4d-631f-4db2-91a9-271a0938abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理\n",
    "begin_time = time()\n",
    "quantize_outputs = quantize_model[0].forward(input_tensor)\n",
    "print(\"\\033[1;31m\" + f\"forward time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e65db5-f4ac-456c-851a-4b883db3a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c to np\n",
    "begin_time = time()\n",
    "s_clses = quantize_outputs[0].buffer\n",
    "s_bboxes = quantize_outputs[1].buffer\n",
    "m_clses = quantize_outputs[2].buffer\n",
    "m_bboxes = quantize_outputs[3].buffer\n",
    "l_clses = quantize_outputs[4].buffer\n",
    "l_bboxes = quantize_outputs[5].buffer\n",
    "print(\"\\033[1;31m\" + f\"c to numpy time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(f\"{s_bboxes.shape = }  {m_bboxes.shape = }  {l_bboxes.shape = }\")\n",
    "print(f\"{s_clses.shape = }   {m_clses.shape = }   {l_clses.shape = }\")\n",
    "\n",
    "print(f\"{s_bboxes.dtype = }  {m_bboxes.dtype = }  {l_bboxes.dtype = }\")\n",
    "print(f\"{s_clses.dtype = }   {m_clses.dtype = }   {l_clses.dtype = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6170c4-34ba-48bc-9455-fe7ac276d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "begin_time = time()\n",
    "s_bboxes = s_bboxes.reshape(-1, REG * 4)\n",
    "m_bboxes = m_bboxes.reshape(-1, REG * 4)\n",
    "l_bboxes = l_bboxes.reshape(-1, REG * 4)\n",
    "s_clses = s_clses.reshape(-1, CLASSES_NUM)\n",
    "m_clses = m_clses.reshape(-1, CLASSES_NUM)\n",
    "l_clses = l_clses.reshape(-1, CLASSES_NUM)\n",
    "print(\"\\033[1;31m\" + f\"reshape time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(f\"{s_bboxes.shape = }  {m_bboxes.shape = }  {l_bboxes.shape = }\")\n",
    "print(f\"{s_clses.shape = }   {m_clses.shape = }   {l_clses.shape = }\")\n",
    "\n",
    "print(f\"{s_bboxes.dtype = }  {m_bboxes.dtype = }  {l_bboxes.dtype = }\")\n",
    "print(f\"{s_clses.dtype = }   {m_clses.dtype = }   {l_clses.dtype = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f297eb-2643-457d-895f-9fb662aab41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify: 利用numpy向量化操作完成阈值筛选（优化版 2.0）\n",
    "begin_time = time()\n",
    "s_max_scores = np.max(s_clses, axis=1)\n",
    "s_valid_indices = np.flatnonzero(s_max_scores >= CONF_THRES_RAW)  # 得到大于阈值分数的索引，此时为小数字\n",
    "s_ids = np.argmax(s_clses[s_valid_indices, : ], axis=1)\n",
    "s_scores = s_max_scores[s_valid_indices]\n",
    "\n",
    "m_max_scores = np.max(m_clses, axis=1)\n",
    "m_valid_indices = np.flatnonzero(m_max_scores >= CONF_THRES_RAW)  # 得到大于阈值分数的索引，此时为小数字\n",
    "m_ids = np.argmax(m_clses[m_valid_indices, : ], axis=1)\n",
    "m_scores = m_max_scores[m_valid_indices]\n",
    "\n",
    "l_max_scores = np.max(l_clses, axis=1)\n",
    "l_valid_indices = np.flatnonzero(l_max_scores >= CONF_THRES_RAW)  # 得到大于阈值分数的索引，此时为小数字\n",
    "l_ids = np.argmax(l_clses[l_valid_indices, : ], axis=1)\n",
    "l_scores = l_max_scores[l_valid_indices]\n",
    "print(\"\\033[1;31m\" + f\"Small, Medium, Big Feature Map Conf Threshold time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(f\"{s_scores.shape = }  {s_ids.shape = }  {s_valid_indices.shape = }\")\n",
    "print(f\"{m_scores.shape = }  {m_ids.shape = }  {m_valid_indices.shape = }\")\n",
    "print(f\"{l_scores.shape = }  {l_ids.shape = }  {l_valid_indices.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c701d17-2a92-49d7-9629-bc8c309b03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3个Classify分类分支：Sigmoid计算\n",
    "begin_time = time()\n",
    "s_scores = 1 / (1 + np.exp(-s_scores))\n",
    "m_scores = 1 / (1 + np.exp(-m_scores))\n",
    "l_scores = 1 / (1 + np.exp(-l_scores))\n",
    "print(\"\\033[1;31m\" + f\"sigmoid time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d80a31-5c27-412a-a3f3-d5dd38c0ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3个Bounding Box分支：反量化\n",
    "begin_time = time()\n",
    "s_bboxes_float32 = s_bboxes[s_valid_indices,:].astype(np.float32) * s_bboxes_scale\n",
    "m_bboxes_float32 = m_bboxes[m_valid_indices,:].astype(np.float32) * m_bboxes_scale\n",
    "l_bboxes_float32 = l_bboxes[l_valid_indices,:].astype(np.float32) * l_bboxes_scale\n",
    "print(\"\\033[1;31m\" + f\"Bounding Box Dequantized time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(f\"{s_bboxes_float32.shape = }\")\n",
    "print(f\"{m_bboxes_float32.shape = }\")\n",
    "print(f\"{l_bboxes_float32.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4fc072-7d47-4ad0-9103-f8b15e1ebb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3个Bounding Box分支：dist2bbox（ltrb2xyxy） transpose\n",
    "begin_time = time()\n",
    "\n",
    "s_ltrb_indices = np.sum(softmax(s_bboxes_float32.reshape(-1, 4, 16), axis=2) * weights_static, axis=2)\n",
    "s_grid_indices = s_grid[s_valid_indices, :]\n",
    "s_x1y1 = s_grid_indices - s_ltrb_indices[:, 0:2]\n",
    "s_x2y2 = s_grid_indices + s_ltrb_indices[:, 2:4]\n",
    "s_dbboxes = np.hstack([s_x1y1, s_x2y2])*8\n",
    "\n",
    "m_ltrb_indices = np.sum(softmax(m_bboxes_float32.reshape(-1, 4, 16), axis=2) * weights_static, axis=2)\n",
    "m_grid_indices = m_grid[m_valid_indices, :]\n",
    "m_x1y1 = m_grid_indices - m_ltrb_indices[:, 0:2]\n",
    "m_x2y2 = m_grid_indices + m_ltrb_indices[:, 2:4]\n",
    "m_dbboxes = np.hstack([m_x1y1, m_x2y2])*16\n",
    "\n",
    "l_ltrb_indices = np.sum(softmax(l_bboxes_float32.reshape(-1, 4, 16), axis=2) * weights_static, axis=2)\n",
    "l_grid_indices = l_grid[l_valid_indices,:]\n",
    "l_x1y1 = l_grid_indices - l_ltrb_indices[:, 0:2]\n",
    "l_x2y2 = l_grid_indices + l_ltrb_indices[:, 2:4]\n",
    "l_dbboxes = np.hstack([l_x1y1, l_x2y2])*32\n",
    "print(\"\\033[1;31m\" + f\"dist2bbox（ltrb2xyxy） time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ed9d6-56ff-4169-983f-2f96a4c50ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大中小特征层阈值筛选结果拼接\n",
    "begin_time = time()\n",
    "dbboxes = np.concatenate((s_dbboxes, m_dbboxes, l_dbboxes), axis=0)\n",
    "scores = np.concatenate((s_scores, m_scores, l_scores), axis=0)\n",
    "ids = np.concatenate((s_ids, m_ids, l_ids), axis=0)\n",
    "\n",
    "## xyxy 2 xyhw\n",
    "xy = (dbboxes[:,2:4] + dbboxes[:,0:2])/2.0\n",
    "hw = (dbboxes[:,2:4] - dbboxes[:,0:2])\n",
    "xyhw = np.hstack([xy, hw])\n",
    "print(\"\\033[1;31m\" + f\"concat time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")\n",
    "\n",
    "print(f\"{dbboxes.shape = }  {scores.shape = }  {ids.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c896e2-269d-47ec-81b7-490625c84981",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(CLASSES_NUM):\n",
    "    id_indices = ids==i\n",
    "    indices = cv2.dnn.NMSBoxes(xyhw[id_indices,:], scores[id_indices], SCORE_THRESHOLD, NMS_THRESHOLD)\n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "    for indic in indices:\n",
    "        x1, y1, x2, y2 = dbboxes[id_indices,:][indic]\n",
    "        # scale and shift\n",
    "        x1 = int((x1 - x_shift) / x_scale)\n",
    "        y1 = int((y1 - y_shift) / y_scale)\n",
    "        x2 = int((x2 - x_shift) / x_scale)\n",
    "        y2 = int((y2 - y_shift) / y_scale)\n",
    "        # clip\n",
    "        x1 = x1 if x1 > 0 else 0\n",
    "        x2 = x2 if x2 > 0 else 0\n",
    "        y1 = y1 if y1 > 0 else 0\n",
    "        y2 = y2 if y2 > 0 else 0\n",
    "        x1 = x1 if x1 < img_w else img_w\n",
    "        x2 = x2 if x2 < img_w else img_w\n",
    "        y1 = y1 if y1 < img_h else img_h\n",
    "        y2 = y2 if y2 < img_h else img_h\n",
    "        results.append((i, scores[id_indices][indic], x1, y1, x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2679eae-a0f9-4748-bf6e-3f1d924c6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制\n",
    "draw_img = img.copy()\n",
    "begin_time = time()\n",
    "for class_id, score, x1, y1, x2, y2 in results:\n",
    "    print(\"(%d, %d, %d, %d) -> %s: %.2f\"%(x1,y1,x2,y2, coco_names[class_id], score))\n",
    "    draw_detection(draw_img, (x1, y1, x2, y2), score, class_id)\n",
    "jshow(draw_img, 10)\n",
    "print(\"\\033[1;31m\" + f\"Draw Result time = {1000*(time() - begin_time):.2f} ms\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17367373-05da-4ce4-9b17-c30c266cf87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5717fa1-de35-4380-bb03-d3c4cc102e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7048c5d-2954-4119-9328-f7c56142815b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779294b1-3816-4bc8-ad66-83b4e6ed59d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b855f-6153-4ae0-811c-e40a6adb919b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84272d7-5d0d-4ca1-b824-9707abc0a04b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
